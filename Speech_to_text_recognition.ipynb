{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1F3yE6Z8NEvb7k7qEhT0OKkwoQpKtWZt8",
      "authorship_tag": "ABX9TyO+sWsCkrUvgef5kopw/mxV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hpatil000/AI_Project/blob/main/Speech_to_text_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn-4Va3u_Idz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, utils, callbacks\n",
        "import librosa\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_dir = '/content/drive/My Drive/Colab Notebooks/dataset/book3/'\n",
        "transcripts_file = '/content/drive/My Drive/Colab Notebooks/dataset/Book3.txt'"
      ],
      "metadata": {
        "id": "jOhdnt0V_RnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcripts = {}\n",
        "with open(transcripts_file, 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split('\\t')\n",
        "        transcripts[parts[0]] = parts[1]\n",
        "print(transcripts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11kUGBnv_Up6",
        "outputId": "b3a1d444-cb4a-4e8e-bb68-8628d1af0a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'LJ001-0001': 'Printing  in the only sense with which we are at present concerned differs from most if not from all the arts and crafts represented in the Exhibition', 'LJ001-0002': 'in being comparatively modern.in being comparatively modern.', 'LJ001-0003': 'For although the Chinese took impressions from wood blocks engraved in relief for centuries before the woodcutters of the Netherlands', 'LJ001-0004': 'produced the block books which were the immediate predecessors of the true printed book', 'LJ001-0005': 'the invention of movable metal letters in the middle of the fifteenth century may justly be considered as the invention of the art of printing.', 'LJ001-0006': 'And it is worth mention in passing that', 'LJ001-0007': 'the earliest book printed with movable types', 'LJ001-0008': 'has never been surpassed.', 'LJ001-0009': 'Printing may be considered as the art of making books by means of movable types.', 'LJ001-0010': 'Now as all books not primarily intended as picture-books consist principally of types composed to form letterpress', 'LJ001-0021': 'The earliest book printed with movable type the aforesaid Gutenberg Bible is printed in letters which are an exact imitation', 'LJ001-0022': '\"of the more formal ecclesiastical writing which obtained at that time; this has since been called \"\"missal type\"', 'LJ001-0052': \"yet their type is artistically on a much lower level than Jenson's and in fact\", 'LJ001-0053': 'they must be considered to have ended the age of fine printing in Italy', 'LJ001-0054': 'Jenson', 'LJ001-0055': 'some of which -- as', 'LJ001-0056': 'It was these great Venetian printers', 'LJ001-0057': \"Parma who produced the splendid editions of the Classics  which are one of the great glories of the printer's art\", 'LJ001-0058': 'and are worthy representatives of the eager enthusiasm for the revived learning of that epoch. By far', 'LJ001-0059': 'the greater part of these Italian printers working under the influence of Italian opinion and aims.', 'LJ001-0060': 'It must be understood that through the whole of the fifteenth and the first quarter of the sixteenth centuries', 'LJ001-0061': 'the Roman letter was used side by side with the Gothic.', 'LJ001-0062': 'Even in Italy most of the theological and law books were printed in Gothic letter', 'LJ001-0063': 'which was generally more formally Gothic than the printing of the German workmen', 'LJ001-0064': 'many of whose types are of a transitional character.', 'LJ001-0065': 'This was notably the case with the early works printed at Ulm', 'LJ001-0066': \"In fact Gunther Zeiner's first type (afterwards used by Schussler) is remarkably like the type of the before-mentioned Subiaco books.\", 'LJ001-0067': 'In the Low Countries and Cologne which were very fertile of printed books Gothic was the favorite.', 'LJ001-0068': 'The characteristic Dutch type as represented by the excellent printer Gerard Leew is very pronounced and uncompromising Gothic.', 'LJ001-0069': \"This type was introduced into England by Wynkyn de Worde Caxton's successor\", 'LJ001-0070': 'and was used there with very little variation all through the sixteenth and seventeenth centuries', 'LJ001-0071': \"Most of Caxton's own types are of an earlier character\", 'LJ001-0072': 'After the end of the fifteenth century the degradation of printing especially in Germany and Italy', 'LJ001-0073': 'went on apace; and by the end of the sixteenth century there was no really beautiful printing done', 'LJ001-0074': 'the best mostly French or Low-Country was neat and clear but without any distinction', 'LJ001-0075': 'the worst which perhaps was the English', 'LJ001-0076': 'and things got worse and worse through the whole of the seventeenth century', 'LJ001-0077': 'In England about this time an attempt was made (notably by Caslon who started business in London as a type-founder in 1720)', 'LJ001-0078': 'to improve the letter in form.', 'LJ001-0079': \"Caslon's type is clear and neat\", 'LJ001-0080': 'he seems to have taken the letter of the Elzevirs of the seventeenth century for his model', 'LJ001-0081': 'type cast from his matrices is still in everyday use.', 'LJ001-0082': 'In spite printing had still one last degradation to undergo.', 'LJ001-0083': 'The seventeenth century founts were bad rather negatively than positively.', 'LJ001-0084': 'But for the beauty of the earlier work they might have seemed tolerable', 'LJ001-0085': 'It was reserved for the founders of the later eighteenth century to produce letters which are positively ugly and which it may be added', 'LJ001-0086': 'are dazzling and unpleasant to the eye owing to the clumsy thickening and vulgar thinning of the lines', 'LJ001-0087': 'for the seventeenth-century letters are at least pure and simple in line. The Italian      and the Frenchman  Didot', 'LJ001-0088': 'were the leaders in this luckless change went much on the same lines;', 'LJ001-0089': 'but his letters', 'LJ001-0090': 'With this change the art of printing touched bottom', 'LJ001-0101': 'It is discouraging to note that the improvement of the last fifty years is almost wholly confined to Great Britain.', 'LJ001-0102': 'Here and there a book is printed in France or Germany with some pretension to good taste', 'LJ001-0103': 'but the general revival of the old forms has made no way in those countries.', 'LJ001-0104': 'Italy is contentedly stagnant.Italy is contentedly stagnant.', 'LJ001-0105': 'LJ001-0105|America has produced a good many showy books', 'LJ001-0106': 'oddity rather than rational beauty and meaning being apparently the thing sought for both in the letters and the illustrations.oddity rather than rational beauty', 'LJ001-0107': 'To say a few words on the principles of design in typography', 'LJ001-0108': 'it is obvious that legibility is the first thing to be aimed at in the forms of the letters', 'LJ001-0109': 'this is best furthered by the avoidance of irrational swellings and spiky projections', 'LJ001-0110': 'Even the Caslon type when enlarged shows great shortcomings in this respect', 'LJ001-0111': 'the ends of many of the letters such as the t and e are hooked up in a vulgar and meaningless way', 'LJ001-0112': \"instead of ending in the sharp and clear stroke of Jenson's letters;instead of ending in the sharp and clear stroke of Jenson's letters;\", 'LJ001-0113': 'there is a grossness in the upper finishings of letters like the c the a and so on', 'LJ001-0114': 'an ugly pear-shaped swelling defacing the form of the letter', 'LJ001-0115': 'in short it happens to this craft  as to others  that the utilitarian practice  though it professes to avoid ornament', 'LJ001-0116': 'still clings to a foolish and is by no means useful;', 'LJ001-0117': 'which title can only be claimed by artistic practice whether the art in it be conscious or unconscious.', 'LJ001-0118': 'In no characters is the contrast between the ugly and vulgar illegibility of the modern type', 'LJ001-0119': 'and the elegance and legibility of the ancient more striking than in the Arabic numerals.', 'LJ001-0120': 'In the old print each figure has its definite individuality', 'LJ001-0121': 'in reading the modern figures the eyes must be strained before the reader can have any reasonable assurancein reading the modern figures the eyes must be straine', 'LJ001-0122': 'that he has a 5      unless the press work is of the best', 'LJ001-0123': \"this is awkward if you have to read Bradshaw's Guide in a hurry.\", 'LJ001-0124': 'One of the differences between the fine type and the utilitarian must probably be put down to a misapprehension of a commercial necessity', 'LJ001-0125': 'this is the narrowing of the modern letters.this is the narrowing of the modern letters.', 'LJ001-0126': \"Most of Jenson's letters are designed within a square\", 'LJ001-0127': 'the modern letters are narrowed by a third or thereabout; but while this gain of space very much hampers the possibility of beauty of design', 'LJ001-0128': 'it is not a real gain which  probably', 'LJ001-0129': 'the lateral compression of his letters renders necessary.', 'LJ001-0130': 'Commercialism again compels the use of type too small in size to be comfortable reading', 'LJ001-0131': '\"the size known as \"\"Long primer\"\" ought to be the smallest size used in a book meant to be read.', 'LJ001-0132': 'Here', 'LJ001-0133': 'One very important matter in \"setting up\" for fine printing is the \"spacing', 'LJ001-0134': 'In good printing the spaces between the words should be as near as possible equal', 'LJ001-0135': 'it is impossible that they should be quite equal except in lines of poetry', 'LJ001-0136': 'modern printers understand this, but it is only practiced in the very best establishments.', 'LJ001-0137': 'But another point which they should attend to they almost always disregard', 'LJ001-0138': 'this is the tendency to the formation of ugly meandering white lines or rivers\"\" in the page', 'LJ001-0139': 'a blemish which can be nearly', 'LJ001-0140': '\"the desirable thing being \"\"the breaking of the line\"\" as in bonding masonry or brickwork', 'LJ001-0141': 'The general solidity of a page is much to be sought forThe general solidity of a page is much to be sought for', 'LJ001-0142': '\"modern printers generally overdo the \"\"whites\"\" in the spacing\"', 'LJ001-0143': 'For where these are boldly and carefully designed', 'LJ001-0144': 'the words may be set much closer together without loss of clearness.', 'LJ001-0145': '\"No definite rules      except the avoidance of \"\"rivers\"\" and excess of white  can be given for the spacing\"', 'LJ001-0146': 'which requires the constant exercise of judgment and taste on the part of the printer.', 'LJ001-0147': 'The position of the page on the paper should be considered if the book is to have a satisfactory look.', 'LJ001-0148': 'Here once more the almost invariable modern practice is in opposition to a natural sense of proportion.', 'LJ001-0149': 'From the time when books first took their present shape till the end of the sixteenth century', 'LJ001-0150': 'the page so lay on the paper that there was more space allowed to the bottom and fore margin than to the top and back of the paper', 'LJ001-0151': 'the unit of the book being looked on as the two pages forming an opening.the unit of the book being looked on as the two pages forming an opening.', 'LJ001-0152': 'The modern printer and prints the page in the middle of his paper', 'LJ001-0153': 'only nominally so', 'LJ001-0154': 'the result as measured by the eye being that the lower margin is less than the top one', 'LJ001-0155': 'and that laterally the page looks as if it were being driven off the paper.', 'LJ001-0156': 'The paper on which the printing is to be done is a necessary part of our subject', 'LJ001-0157': 'of this it may be said that though there is some good paper made now', 'LJ001-0158': ' although it would not materially increase the cost in all but the very cheapest.', 'LJ001-0159': 'The paper that is used for ordinary books is exceedingly bad even in this country but is beaten in the race for vileness', 'LJ001-0160': 'by that made in America', 'LJ001-0161': 'There seems to be no reason why ordinary paper should not be better made', 'LJ001-0162': 'even allowing the necessity for a very low price; but any improvement must be based on showing openly that the cheap article is cheap', 'LJ001-0163': 'e.g. the cheap paper should not sacrifice toughness and durability to a smooth and white surface', 'LJ001-0164': 'which should be indications of a delicacy of material and manufacture which would of necessity increase its cost.', 'LJ001-0165': 'One fruitful source of badness in paperOne fruitful source of badness in paper', 'LJ001-0166': 'is the habit that publishers have of eking out a thin volume by printing it on thick paper almost of the substance of cardboard', 'LJ001-0167': 'a device which deceives nobody and makes a book very unpleasant to read.', 'LJ001-0168': 'On the whole', 'LJ001-0169': 'The paper used for printing the small highly ornamented French service-books about the beginning of the sixteenth century is a model in this respect', 'LJ001-0170': 'being thin tough and opaque.', 'LJ001-0171': 'However', 'LJ001-0172': 'The ornamentation of printed books is too wide a subject to be dealt with fully here; but one thing must be said on it.The ornamentation of printed books is too', 'LJ001-0173': 'The essential point to be remembered is that the ornament      whether picture or pattern-work  should form part of the page', 'LJ001-0174': 'should be a part of the whole scheme of the book.should be a part of the whole scheme of the book.', 'LJ001-0175': 'Simple as this proposition is', 'LJ001-0176': 'because the modern practice is to disregard the relation between the printing and the ornament altogether', 'LJ001-0177': 'so that if the two are helpful to one another it is a mere matter of accident.so that if the two are helpful to one another it is a mere matter of accident.', 'LJ001-0178': 'The due relation of letter to pictures and other ornament was thoroughly understood by the old printers; so thatThe due relation of letter to pictures and other', 'LJ001-0179': 'even when the woodcuts are very rude indeed', 'LJ001-0180': 'the proportions of the page still give pleasure by the sense of richness that the cuts and letter together convey.the proportions of the page still give pleasure', 'LJ001-0181': 'When', 'LJ001-0182': 'the books so ornamented are amongst the most delightful works of art that have ever been produced.the books so ornamented are amongst the most delightful works o', 'LJ001-0183': 'Therefore      due spacing of the lines and words  and proper position of the page on the paper', 'LJ001-0184': 'all books might be at least comely and well-looking: and if to these good qualities were added really beautiful ornament and pictures', 'LJ001-0185': 'printed books might once again illustrate to the fullprinted books might once again illustrate to the full', 'LJ001-0186': 'the position of our Society that a work of utility might be also a work of art'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_data = []\n",
        "transcription_data = []\n"
      ],
      "metadata": {
        "id": "bUkpL_Nz_XIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in os.listdir(audio_dir):\n",
        "    if file_name.endswith('.wav'):\n",
        "        \n",
        "        file_path = os.path.join(audio_dir, file_name)\n",
        "        \n",
        "        audio, sr = librosa.load(file_path, sr=None, mono=True)\n",
        "    \n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
        "\n",
        "        mfccs = np.mean(mfccs.T, axis=0)\n",
        "\n",
        "        audio_data.append(mfccs)\n",
        "        file_id = os.path.splitext(file_name)[0]\n",
        "        transcription = transcripts.get(file_id, '')\n",
        "        \n",
        "        \n",
        "        transcription_data.append(transcription)\n",
        "print(transcription_data)\n",
        "print(audio_data)"
      ],
      "metadata": {
        "id": "brb-6CrLC8qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(transcription_data)\n",
        "num_classes = len(tokenizer.word_index) + 1\n",
        "transcription_data = tokenizer.texts_to_matrix(transcription_data, mode='binary')\n",
        "print(transcription_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL76B5TJ_oka",
        "outputId": "9511001d-3ed8-431e-f914-5fd8d476c987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_data = np.array(audio_data)\n",
        "transcription_data = np.array(transcription_data)\n",
        "print(audio_data)\n",
        "print(transcription_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay2mAy1z_6OE",
        "outputId": "ada82f64-b699-4388-b678-6a219b6b4d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.13856079e+02  7.97911911e+01 -1.26718531e+01 ...  1.32483339e+00\n",
            "  -2.49886572e-01  1.29973650e+00]\n",
            " [-2.95998016e+02  7.07941284e+01 -9.36836052e+00 ...  2.11066651e+00\n",
            "   2.65832067e-01  1.99329877e+00]\n",
            " [-2.99330139e+02  6.53351593e+01  1.08323593e+01 ...  1.36216831e+00\n",
            "  -1.66670787e+00  1.94644228e-01]\n",
            " ...\n",
            " [-2.90156555e+02  7.17155533e+01  4.96193218e+00 ...  8.49238992e-01\n",
            "  -2.23540640e+00  1.83953476e+00]\n",
            " [-2.91123596e+02  7.95055466e+01 -1.75643909e+00 ...  7.66244590e-01\n",
            "  -9.73294556e-01  1.55638421e+00]\n",
            " [-2.81546112e+02  7.48598480e+01 -1.20056715e+01 ...  2.40486288e+00\n",
            "  -7.69369006e-01  8.22053611e-01]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_index = int(0.9 * len(audio_data))\n",
        "train_audio = audio_data[:split_index]\n",
        "print(transcription_data[:split_index])\n",
        "\n",
        "train_transcription = transcription_data[:split_index]\n",
        "test_audio = audio_data[split_index:]\n",
        "test_transcription = transcription_data[split_index:]\n",
        "#print(transcription_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1ibBG_K_9v2",
        "outputId": "8939deae-22c9-46fa-d053-d1806986b50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(512, input_shape=(40,), activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "qrkU_S15ABLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "juKgpaBCADtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_callback = callbacks.EarlyStopping(patience=10, monitor='val_loss', restore_best_weights=True)"
      ],
      "metadata": {
        "id": "jsN8rxjOAHm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(train_audio)\n",
        "#print(train_transcription)\n",
        "model.fit(train_audio, train_transcription, validation_split=0.2, epochs=10, batch_size=32, callbacks=[early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqxJy7qJAKnn",
        "outputId": "17c11b4b-080d-4c2c-a62e-e7dcf07017c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 93ms/step - loss: 356.4153 - accuracy: 0.0714 - val_loss: 483.1043 - val_accuracy: 0.7200\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 499.2953 - accuracy: 0.4184 - val_loss: 786.0134 - val_accuracy: 0.0400\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 783.6014 - accuracy: 0.2245 - val_loss: 1158.3846 - val_accuracy: 0.0400\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1082.3173 - accuracy: 0.2857 - val_loss: 1708.3900 - val_accuracy: 0.7200\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 1499.3416 - accuracy: 0.3878 - val_loss: 2530.5085 - val_accuracy: 0.7200\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2137.2332 - accuracy: 0.3571 - val_loss: 3639.9963 - val_accuracy: 0.7200\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 2843.7097 - accuracy: 0.5102 - val_loss: 4906.2412 - val_accuracy: 0.7200\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 3818.3469 - accuracy: 0.3469 - val_loss: 6517.2988 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 5100.8672 - accuracy: 0.1122 - val_loss: 8905.2402 - val_accuracy: 0.0400\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 6884.1006 - accuracy: 0.1837 - val_loss: 12446.3662 - val_accuracy: 0.7200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3bc1bb3fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_audio, test_transcription)\n",
        "print(f'Test loss: {loss:.3f}, test accuracy: {accuracy:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tfnX8wHAeu3",
        "outputId": "8713f8ca-615d-424a-80bf-df70537f509f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step - loss: 14911.9707 - accuracy: 0.8571\n",
            "Test loss: 14911.971, test accuracy: 0.857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = len(audio)\n",
        "print(\"num_samples:\", num_samples)\n",
        "chunk_size = 10\n",
        "num_chunks = int(np.ceil(num_samples  / ( sr * chunk_size) ))\n",
        "num_chunks = 10\n",
        "print(\"num_chunks:\", num_chunks)\n",
        "transcriptions = []\n",
        "for i in range(num_chunks):\n",
        "  start_index = i*sr*chunk_size\n",
        "  end_index =  min(start_index +sr*chunk_size, num_samples)\n",
        "  mfccs = librosa.feature.mfcc(y=audio[start_index:end_index], sr=sr, n_mfcc=40)\n",
        "  mfccs = np.mean(mfccs.T, axis=0)\n",
        "  prediction = model.predict(np.array([mfccs]))\n",
        "  transcription = tokenizer.sequences_to_texts([[np.argmax(prediction)]])\n",
        "  transcriptions.append(transcription)\n",
        "\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mNmIiHGAlts",
        "outputId": "a941675e-55e6-4d10-e5ac-90b71395e9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_samples: 158109\n",
            "num_chunks: 10\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=0\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "['the']\n"
          ]
        }
      ]
    }
  ]
}